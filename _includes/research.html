<h2>REsearch</h2>
<div style="height: 10px"></div>

</table>
<table id="tbPublications" width="100%" cellspacing='0'>
	<tbody> 
	<!--########################-->
	<tr style="width: 100%;" style="padding: 10px">
		<td width="200px" style="padding-top: 10px; padding-bottom: 10px">
			<div class="container">
				<img src="./files/work/RL.png" width="180px" style="box-shadow: 4px 4px 4px #888888;  margin-left: 10px; margin-right: 10px;">
				<!-- <div class="arxiv-label" style="margin-left: 10px; width: 80px;">Under Review</div> -->
			</div>
		</td>				
		<td style="padding: 10px">
			<!-- <div style="height: 10px"></div> -->
			<b style="font-size: 15px; color: #456fc3;">A Survey on Custom Hardware for Deep Reinforcement Learning</b>
			<div style="height: 5px;"></div>
			<div style="font-size: 12px">Supervisor: <a href="https://www.ece.mcmaster.ca/~ameer/" target="_blank">Prof. Ameer Abdelhadi</a></div>
			<div style="height: 5px;"></div>
			<div style="font-size: 12px">07/2024 ~ 09/2024, McMaster University (onsite)</div>
			<div style="height: 5px;"></div>
			<div style="font-size: 12px">Defense: 10/23/2024</div>
			<div style="height: 5px;"></div>
			<div style="font-size: 12px; color: gray;">This survey explores the development of domain-specific architectures for reinforcement learning (RL), highlighting advancements and challenges in implementing RL on specialized hardware. As RL algorithms grow more complex and computationally intensive, custom hardware solutions offer promising pathways to enhance performance, energy efficiency, and scalability. We review different architectures designed to accelerate RL algorithms as well as key contributions for various fields such as IoT applications, hardware prefetching and processors. Previous work primarily focused on either FPGA or GPU implementations, lacking extensive performance comparisons across various RL algorithms and configurations especially the modern ones. They also lack detailed discussions on integrating advanced neural network layers like CNNs and RNNs in FPGA designs. Our survey addresses these gaps by providing a comprehensive comparison of FPGA and GPU implementations, emphasizing fine-grained parallelism, on-chip memory usage, and integration with software-based environments. Furthermore, we explore near-memory computing and state-of-the-art DRL algorithms on custom hardware. We conclude with future research directions, including integrating advanced neural network layers in FPGA designs and exploring near-memory computing to further enhance RL capabilities on custom hardware.</div>
			<div style="height: 5px"></div>
			<div style="font-size: 12px"><a href="https://docs.google.com/presentation/d/1544WAm2EHhHOehCn_1tD_X8nah5iFhl-/edit?usp=sharing&ouid=104543543746240617362&rtpof=true&sd=true" target="_blank">Defense PPT in Chinese</a></div>
			<div style="height: 10px"></div>			
		</td>
	</tr>
	</tbody>
</table>
